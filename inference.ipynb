{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.1))\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu',))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_processing(img_path):\n",
    "    img = load_img(img_path, target_size=(48, 48))\n",
    "    img = img_to_array(img)\n",
    "    if img.shape[-1] == 3:\n",
    "        img = tf.image.rgb_to_grayscale(img)\n",
    "\n",
    "    img = img[..., 0][np.newaxis, ...]\n",
    "    # img = tf.expand_dims(img, axis = 0)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\miniconda3\\envs\\venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights('weights/Facial_Expression_Recognition.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step\n",
      "[[2.03220150e-03 1.45870345e-05 1.86470075e-04 8.09812665e-01\n",
      "  1.85925648e-01 1.95530825e-03 7.30564498e-05]]\n",
      "Predicted class : happy\n"
     ]
    }
   ],
   "source": [
    "input_img = image_processing('F:/machine_learning/projects/face_expression/archive/s.png')\n",
    "print(input_img.shape)\n",
    "predictions = model.predict(input_img)\n",
    "print(predictions)\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(f'Predicted class : {classes[predicted_class]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
